"""
D√âTECTEUR DE RUMEURS - VERSION AM√âLIOR√âE
Am√©liorations:
1. Topics configurables (JSON ou param√®tres API)
2. Score de viralit√© corrig√© (5 apparitions = viral)
3. Filtrage strict sur le B√©nin uniquement
4. Les rumeurs non-virales ne sont PAS enregistr√©es
"""

import os
import json
import logging
import time
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional
import requests
from dotenv import load_dotenv
from typing import Optional
import re

load_dotenv()

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except Exception:
    GEMINI_AVAILABLE = False

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

# ==========================================
# CONFIGURATION
# ==========================================
class Config:
    GOOGLE_SEARCH_API_KEY = os.getenv("GOOGLE_SEARCH_API_KEY", "")
    GOOGLE_SEARCH_ENGINE_ID = os.getenv("GOOGLE_SEARCH_ENGINE_ID", "")
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

    # Sites FIABLES (pour V√âRIFIER les rumeurs)
    TRUSTED_SOURCES = [
        # --- M√©dias b√©ninois principaux ---
        "beninwebtv.com",
        "beninpolitique.org",
        "lematinal.bj",
        "ortb.bj",
        "lanouvelletribune.info",
        "lanation.bj",
        "24haubenin.info",
        "actubenin.com",
        "matinlibre.com",
        "lepoint.bj",
        "la-quotidienne.bj",
        "banouto.bj",
        "fraternitefj.com",
        "fraternitefm.bj",
        "jupiterinfo.bj",
        "firstafriquetv.bj",
        "leleaderinfobenin.bj",
        "gueritetvmonde.bj",
        "bjnews.bj",
        "diffo.net",
        "lepotentiel.bj",
        "eketinmagazine.com",

        # --- M√©dias panafricains fiables ---
        "rfi.fr",
        "fr.news.yahoo.com",
        "bbc.com",
        "dw.com",
        "jeuneafrique.com",
        "africanews.com",
        "rtb.bf",   # Burkina Faso (souvent repris au B√©nin)
        "lefaso.net",
        "linfodrome.com",   # C√¥te d‚ÄôIvoire s√©rieux
        "seneweb.com",      # S√©n√©gal
        "lequotidien.sn",

        # --- Fact-checkers (tr√®s importants pour ton syst√®me !) ---
        "africacheck.org",
        "benincheck.info",      # (site existant dans certains projets)
        "dubawa.org",           # Afrique de l‚ÄôOuest
        "factcheck.org",
        "fullfact.org",
        "snopes.com",

        # --- Institutions b√©ninoises ---
        "gouv.bj",
        "presidence.bj",
        "assemblee-nationale.bj",
        "justice.gouv.bj",
        "finances.bj",
        "msp.bj",               # Minist√®re de la Sant√©
        "interieur.gouv.bj",
        "police.bj",

        # --- Organisations internationales ---
        "who.int",
        "un.org",
        "worldbank.org",
        "imf.org",
        "unodc.org",
        "ecowas.int",
    ]


    # Sites √† IGNORER compl√®tement
    BLACKLIST = ["archive.org", "webcache.googleusercontent.com"]
    
    OUTPUT_FILE = "rumors_detected.json"
    TOPICS_FILE = "topics.json"  # Fichier de configuration des topics
    RECENT_DAYS = 360
    # Limites pour prot√©ger l'API de recherche (par d√©faut raisonnable)
    MAX_SEARCH_REQUESTS = 10
    QUERY_DELAY = 2.0 # secondes entre requ√™tes
    
    # NOUVEAU: Score de viralit√© corrig√©
    VIRALITY_THRESHOLD = 0.50  # Seuil minimal pour v√©rifier (50%)
    MIN_OCCURRENCES_FOR_VIRAL = 5  # 5 apparitions = r√©ellement viral
    
    # NOUVEAU: Mots-cl√©s B√©nin (filtrage intelligent)
    BENIN_KEYWORDS = [
        # Pays
        "b√©nin", "benin", "b√©ninois", "beninois", "b√©ninoises",
        # Villes principales
        "cotonou", "cotonnou", "porto-novo", "porto novo", "parakou",
        "abomey", "bohicon", "natitingou", "djougou", "lokossa", "ouidah",
        # R√©gions
        "ou√©m√©", "atlantique", "borgou", "zou", "mono", "couffo", 
        "collines", "plateau", "atacora", "donga", "alibori", "littoral",
        # Personnalit√©s et institutions
        "patrice talon", "talon", "gouvernement b√©ninois", "ceni b√©nin",
        "assembl√©e nationale b√©nin", "pr√©sidence b√©nin"
    ]
    
    # Topics par d√©faut si aucun fichier n'est fourni
    DEFAULT_TOPICS = {
        "politique": ["Patrice Talon", "CENI", "√©lections", "gouvernement b√©ninois"],
        "sant√©": ["vaccination B√©nin", "chol√©ra B√©nin", "paludisme B√©nin"],
        "√©conomie": ["carburant B√©nin", "prix B√©nin", "CFA"],
        "s√©curit√©": ["s√©curit√© B√©nin", "braquage Cotonou"]
    }


def domain_of_url(url: str) -> str:
    """Extrait le domaine d'une URL"""
    if not url:
        return ""
    try:
        from urllib.parse import urlparse
        host = urlparse(url).hostname or ""
        host = host.lower()
        if host.startswith("www."):
            host = host[4:]
        return host
    except Exception:
        return url.lower()


def is_about_benin(text: str) -> bool:
    """
    NOUVEAU: V√©rifie si le texte concerne vraiment le B√©nin
    Approche flexible : cherche mentions du B√©nin
    """
    if not text:
        return False
    
    text_lower = text.lower()
    
    # Enlever accents pour une meilleure d√©tection
    import unicodedata
    text_normalized = unicodedata.normalize('NFD', text_lower)
    text_normalized = ''.join(c for c in text_normalized if unicodedata.category(c) != 'Mn')
    
    # Chercher dans le texte original ET normalis√©
    for keyword in Config.BENIN_KEYWORDS:
        keyword_normalized = unicodedata.normalize('NFD', keyword.lower())
        keyword_normalized = ''.join(c for c in keyword_normalized if unicodedata.category(c) != 'Mn')
        
        if keyword in text_lower or keyword_normalized in text_normalized:
            return True
    
    return False


# ==========================================
# GEMINI EMBEDDINGS
# ==========================================
class GeminiEmbedder:
    def __init__(self, api_key: str):
        self.api_key = api_key
        if GEMINI_AVAILABLE and api_key:
            genai.configure(api_key=api_key)
    
    def embed_text(self, text: str) -> List[float]:
        if not GEMINI_AVAILABLE or not self.api_key:
            return [float(hash(text) % 1000) / 1000.0]
        
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=text,
                task_type="retrieval_document"
            )
            return result['embedding']
        except Exception as e:
            logging.error(f"Embedding error: {e}")
            return [float(hash(text) % 1000) / 1000.0]
    
    @staticmethod
    def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
        try:
            dot_prod = sum(a * b for a, b in zip(vec1, vec2))
            norm1 = sum(a * a for a in vec1) ** 0.5
            norm2 = sum(b * b for b in vec2) ** 0.5
            if norm1 == 0 or norm2 == 0:
                return 0.0
            return float(dot_prod) / (norm1 * norm2)
        except Exception:
            return 0.0


# ==========================================
# D√âDUPLICATEUR
# ==========================================
class RumorDeduplicator:
    def __init__(self, similarity_threshold: float = 0.85):
        self.embedder = GeminiEmbedder(Config.GEMINI_API_KEY)
        self.rumor_embeddings = []
        self.similarity_threshold = similarity_threshold
    
    def is_duplicate(self, rumor_text: str) -> bool:
        if not rumor_text.strip():
            return True
        
        new_emb = self.embedder.embed_text(rumor_text)
        
        for entry in self.rumor_embeddings:
            sim = self.embedder.cosine_similarity(new_emb, entry["embedding"])
            if sim >= self.similarity_threshold:
                logging.info(f"   Duplicate (sim: {sim:.2f})")
                return True
        
        self.rumor_embeddings.append({
            "text": rumor_text,
            "embedding": new_emb,
            "date_added": datetime.now().isoformat()
        })
        return False


# ==========================================
# EXTRACTEUR DE RUMEURS
# ==========================================
class RumorExtractor:
    """D√©tecte les rumeurs dans les r√©sultats de recherche"""
    
    RUMOR_INDICATORS = [
        "rumeur", "info ou intox", "est-ce vrai", "circule",
        "on dit que", "selon des sources", "non confirm√©",
        "aurait", "para√Æt que", "fake news"
    ]
    
    DEMENTI_KEYWORDS = [
        "d√©ment", "d√©menti", "r√©fute", "fausse rumeur",
        "clarification", "mise au point", "infirme"
    ]
    
    @classmethod
    def is_rumor_candidate(cls, text: str) -> bool:
        """V√©rifie si c'est une rumeur potentielle"""
        text_lower = text.lower()
        
        if any(kw in text_lower for kw in cls.DEMENTI_KEYWORDS):
            return False
        
        return any(ind in text_lower for ind in cls.RUMOR_INDICATORS)
    

    @classmethod
    def extract_rumor_text(cls, title: str, snippet: str) -> Optional[str]:
        """Extrait le texte complet de la rumeur sans tronquer"""
        # Concat√®ne titre + snippet
        full_text = f"{title} {snippet}".strip()

        # V√©rifie que c'est une rumeur potentielle
        if not cls.is_rumor_candidate(full_text):
            return None

        # Nettoyage minimal : enlever dates et URLs, mais pas tronquer
        clean = re.sub(r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}', '', full_text)
        clean = re.sub(r'http\S+', '', clean)
        clean = re.sub(r'\s+', ' ', clean).strip()

        # Retourne tout le texte disponible
        return clean if len(clean) > 20 else None


# ==========================================
# VIRALITY SCORER (CORRIG√â)
# ==========================================
class ViralityScorer:
    """
    NOUVEAU: Score de viralit√© corrig√©
    5 apparitions = 1.0 (100% viral)
    """
    def score(self, rumor_text: str, occurrences: int) -> float:
        """
        Calcule un score de viralit√© entre 0 et 1
        - occurrences: nombre de sites o√π la rumeur appara√Æt
        - 5 occurrences = 100% viral
        """
        # Score de base: 5 sources = 100%
        base = min(occurrences / Config.MIN_OCCURRENCES_FOR_VIRAL, 1.0)
        
        # Bonus selon mots viraux
        viral_words = ["circule", "buzz", "choc", "explose", "panique", "alerte"]
        bonus = 0.1 * sum(1 for w in viral_words if w in rumor_text.lower())
        
        return min(base + bonus, 1.0)


def jaccard_similarity(a: str, b: str) -> float:
    """Compute Jaccard similarity on word tokens"""
    import re
    a_set = set(re.findall(r"\w+", (a or "").lower()))
    b_set = set(re.findall(r"\w+", (b or "").lower()))
    if not a_set or not b_set:
        return 0.0
    return len(a_set & b_set) / len(a_set | b_set)


# ==========================================
# QUERY GENERATOR (AVEC TOPICS CONFIGURABLES)
# ==========================================
class QueryGenerator:
    """
    NOUVEAU: G√©n√®re des requ√™tes bas√©es sur des topics configurables
    """
    def __init__(self, topics: Optional[Dict[str, List[str]]] = None):
        """
        Args:
            topics: Dictionnaire {categorie: [liste de topics]}
                   Si None, utilise les topics par d√©faut
        """
        if topics is None:
            # Essayer de charger depuis le fichier
            topics = self.load_topics_from_file()
        
        self.topics = topics or Config.DEFAULT_TOPICS
        
        # Indicateurs de rumeurs (pour certaines requ√™tes)
        self.rumor_indicators = ["rumeur", "info ou intox", "circule", "fake news"]
        
        # Mots-cl√©s g√©n√©raux pour trouver aussi de l'actualit√© r√©cente
        self.general_indicators = ["actualit√©", "news", "derni√®re minute", "breaking"]
        
        # Compatibilit√©: regrouper tous les indicateurs dans `self.indicators`
        # (la m√©thode generate_queries utilisait `self.indicators`)
        self.indicators = self.rumor_indicators + self.general_indicators
        
        logging.info(f"üìã Topics charg√©s: {list(self.topics.keys())}")
    
    @staticmethod
    def load_topics_from_file(filename: str = Config.TOPICS_FILE) -> Optional[Dict]:
        """Charge les topics depuis un fichier JSON"""
        if not os.path.exists(filename):
            logging.info(f"‚ö†Ô∏è  Fichier {filename} non trouv√©, utilisation des topics par d√©faut")
            return None
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                topics = json.load(f)
            logging.info(f"‚úÖ Topics charg√©s depuis {filename}")
            return topics
        except Exception as e:
            logging.error(f"‚ùå Erreur lecture {filename}: {e}")
            return None
    
    def generate_queries(self, max_queries: int = 10) -> List[str]:
        """G√©n√®re des requ√™tes de recherche"""
        queries = []
        
        # NOUVEAU: G√©n√©rer VRAIMENT jusqu'√† max_queries
        for category, topics in self.topics.items():
            for topic in topics:  # TOUS les topics, pas juste [:4]
                for indicator in self.indicators:  # TOUS les indicateurs
                    # Ajouter "B√©nin" dans la requ√™te
                    query = f'"{topic}" "{indicator}" B√©nin -site:gouv.bj'
                    queries.append(query)
                    
                    if len(queries) >= max_queries:
                        return queries[:max_queries]
        
        return queries
    
    @staticmethod
    def save_default_topics(filename: str = Config.TOPICS_FILE):
        """Sauvegarde les topics par d√©faut dans un fichier (utilitaire)"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(Config.DEFAULT_TOPICS, f, ensure_ascii=False, indent=2)
        logging.info(f"‚úÖ Topics par d√©faut sauvegard√©s dans {filename}")


# ==========================================
# WEB SEARCHER
# ==========================================
class WebSearcher:
    def __init__(self, api_key: str, engine_id: str, max_requests: Optional[int] = None, query_delay: float = 0.5):
        self.api_key = api_key
        self.engine_id = engine_id
        self._max_requests = max_requests
        self._requests_made = 0
        self._query_delay = query_delay
    
    def search(self, query: str, num_results: int = 10) -> List[Dict]:
        """Recherche sur le web"""
        if not self.api_key:
            return []
        params = {
            "key": self.api_key,
            "cx": self.engine_id,
            "q": query,
            "num": min(num_results, 10)
        }

        # Retry with exponential backoff on 429 or transient network errors
        max_retries = 3
        backoff = 1
        url = "https://www.googleapis.com/customsearch/v1"

        for attempt in range(1, max_retries + 1):
            # Respect global max requests budget
            if self._max_requests is not None and self._requests_made >= self._max_requests:
                logging.warning(f"Search budget exhausted ({self._requests_made}/{self._max_requests}); skipping query.")
                return []

            # Optional delay between queries to avoid burst
            if self._query_delay and attempt == 1:
                time.sleep(self._query_delay)
            try:
                resp = requests.get(url, params=params, timeout=12)
                # Count this request attempt
                self._requests_made += 1

                # Handle explicit 429 with Retry-After if provided
                if resp.status_code == 429:
                    retry_after = resp.headers.get("Retry-After")
                    try:
                        wait = int(retry_after) if retry_after is not None else backoff
                    except Exception:
                        wait = backoff
                    logging.warning(f"Search 429 Too Many Requests; retrying after {wait}s (attempt {attempt}/{max_retries})")
                    time.sleep(wait)
                    backoff *= 2
                    continue

                resp.raise_for_status()
                data = resp.json()

                return [
                    {
                        "title": item.get("title", ""),
                        "snippet": item.get("snippet", ""),
                        "link": item.get("link", ""),
                        "displayLink": item.get("displayLink", "")
                    }
                    for item in data.get("items", [])
                ]

            except requests.exceptions.RequestException as e:
                logging.error(f"Search error (attempt {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    logging.info(f"Retrying in {backoff}s...")
                    time.sleep(backoff)
                    backoff *= 2
                    continue
                else:
                    logging.error("Max retries reached for search; giving up on this query.")
                    return []

        return []


# ==========================================
# FACT CHECKER
# ==========================================
from bs4 import BeautifulSoup
class ImprovedFactChecker:
    """Fact-checker avec fetch complet des pages et analyse Gemini intelligente"""
    
    def __init__(self, api_key: Optional[str], searcher):
        self.api_key = os.getenv("GEMINI_API_KEY", "")
        self.searcher = searcher
        
        if not api_key:
            logging.error("‚ùå GEMINI_API_KEY manquante - V√©rification impossible!")
            self.gemini_available = False
        elif not GEMINI_AVAILABLE:
            logging.error("‚ùå Module google.generativeai non install√©!")
            self.gemini_available = False
        else:
            try:
                genai.configure(api_key=api_key)
                self.gemini_available = True
                logging.info("‚úÖ Gemini configur√© et pr√™t")
            except Exception as e:
                logging.error(f"‚ùå Erreur configuration Gemini: {e}")
                self.gemini_available = False
    
    # ==========================================
    # √âTAPE 1: RECHERCHE DE SOURCES FIABLES
    # ==========================================

    def _generate_search_queries(self, rumor_text: str) -> List[str]:
        """
        Transforme n'importe quelle rumeur en plusieurs requ√™tes Google.
        Utilise :
        - Extraction de mots-cl√©s (lieux, sujets, personnes)
        - Reformulations simples
        - Optionnel : appel √† Gemini pour reformuler
        """
        # √âtape 1: extraction brute de mots importants
        tokens = re.findall(r"\b\w+\b", rumor_text.lower())
        keywords = [t for t in tokens if len(t) > 4]

        # √âtape 2: requ√™te brute
        queries = [" ".join(keywords[:6])]

        # √âtape 3: cr√©er 2-3 variantes simples
        queries.append(" ".join(keywords[:6]) + " actualit√©")
        queries.append(" ".join(keywords[:6]) + " info")
        queries.append(" ".join(keywords[:6]) + " rumeur")

        # √âtape 4: Option Gemini pour g√©n√©rer 3-5 requ√™tes alternatives si dispo
        if self.gemini_available:
            try:
                model = genai.GenerativeModel("gemini-2.5-flash")
                prompt = f"""
                Reformule la rumeur suivante en 5 requ√™tes Google optimis√©es pour rechercher
                des articles fiables. Ne renvoie que les requ√™tes, pas de phrases.
                
                Rumeur :
                {rumor_text}
                """
                resp = model.generate_content(prompt)
                for line in resp.text.split("\n"):
                    q = line.strip("-‚Ä¢ ").strip()
                    if len(q) > 5:
                        queries.append(q)
            except Exception:
                pass

        # Retirer doublons et limiter
        final_queries = list(dict.fromkeys(queries))
        return final_queries[:8]

    
    def find_trusted_sources(self, rumor_text: str) -> List[Dict]:
        logging.info(f"üîç Recherche pour : {rumor_text[:80]}")
        queries = self._generate_search_queries(rumor_text)
        logging.info(f"üîë Requ√™tes g√©n√©r√©es : {queries}")

        all_results = []

        for q in queries:
            try:
                logging.info(f"üì° Recherche Google : {q}")
                res = self.searcher.search(q, num_results=10)
                all_results.extend(res)
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Erreur requ√™te {q}: {e}")

        # Filtrer par sources fiables
        trusted, partial = [], []
        for result in all_results:
            domain = self._extract_domain(result.get("link", ""))
            if domain in Config.TRUSTED_SOURCES:
                trusted.append(result)
            elif domain.endswith(".bj"):
                partial.append(result)

        final = trusted + partial
        logging.info(f"üìä Total fiables trouv√©s : {len(final)}")
        return final[:10]

    
    # ==========================================
    # EXTRACTION DE MOTS-CL√âS
    # ==========================================

    def _extract_keywords(self, text: str) -> str:
        """
        Extraction intelligente des mots-cl√©s.
        Utilise Gemini si disponible, sinon fallback simple.
        """
        # Si Gemini n‚Äôest pas dispo
        if not self.gemini_available:
            # Fallback simple : garder mots > 4 lettres
            tokens = re.findall(r"\b\w+\b", text.lower())
            filtered = [t for t in tokens if len(t) > 4]
            return " ".join(filtered[:6])  # max 6 mots

        try:
            model = genai.GenerativeModel("gemini-2.5-flash")
            prompt = f"""
            Extrait les mots-cl√©s principaux de ce texte.
            Retourne UNIQUEMENT une liste de 3 √† 7 mots-cl√©s s√©par√©s par des espaces.

            Texte :
            {text}
            """
            response = model.generate_content(prompt)
            keywords = response.text.strip()


            # Nettoyage
            keywords = re.sub(r"[^a-zA-Z0-9√Ä-√ø \-]", "", keywords)
            return keywords

        except:
            # Si Gemini crashe, fallback simple
            tokens = re.findall(r"\b\w+\b", text.lower())
            filtered = [t for t in tokens if len(t) > 4]
            return " ".join(filtered[:6])
        

    @staticmethod
    def _extract_domain(url: str) -> str:
        """Extrait le domaine d'une URL"""
        if not url:
            return ""
        try:
            from urllib.parse import urlparse
            host = urlparse(url).hostname or ""
            host = host.lower()
            if host.startswith("www."):
                host = host[4:]
            return host
        except Exception:
            return ""

    # ==========================================
    # √âTAPE 2: FETCH COMPLET DES PAGES
    # ==========================================
    
    def fetch_full_content(self, url: str) -> Optional[str]:
        """
        R√©cup√®re le contenu COMPLET d'une page web
        (pas juste le snippet Google)
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (compatible; FactCheckBot/1.0)',
                'Accept': 'text/html,application/xhtml+xml',
                'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8'
            }
            
            response = requests.get(url, headers=headers, timeout=10, allow_redirects=True)
            response.raise_for_status()
            
            # Parser avec BeautifulSoup
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extraire le texte de l'article (supprimer scripts, styles, etc.)
            for script in soup(["script", "style", "nav", "footer", "header"]):
                script.decompose()
            
            # R√©cup√©rer le texte principal
            text = soup.get_text(separator=' ', strip=True)
            
            # Nettoyer
            text = re.sub(r'\s+', ' ', text)
            text = text[:8000]  # Limiter √† 8000 caract√®res (pour Gemini)
            
            logging.info(f"      ‚úÖ Fetch√©: {len(text)} caract√®res de {url[:50]}...")
            return text
        
        except Exception as e:
            logging.warning(f"      ‚ö†Ô∏è Erreur fetch {url[:50]}: {e}")
            return None
    
    def fetch_all_sources(self, sources: List[Dict]) -> List[Dict]:
        """Fetch le contenu complet de toutes les sources"""
        enriched_sources = []
        
        for src in sources[:5]:  # Limiter √† 5 pour √©viter trop de requ√™tes
            url = src.get("link", "")
            if not url:
                continue
            
            full_content = self.fetch_full_content(url)
            
            enriched_sources.append({
                "url": url,
                "domain": src.get("displayLink", ""),
                "title": src.get("title", ""),
                "snippet": src.get("snippet", ""),
                "full_content": full_content or src.get("snippet", "")  # Fallback sur snippet
            })
        
        return enriched_sources
    

    def _fallback_verification(self, rumor_text: str, trusted_sources: List[Dict]) -> Dict:
        """
        Fallback simple si Gemini n'est pas dispo ou erreur
        Bas√© sur la pr√©sence de mots-cl√©s dans les snippets
        """
        positive_indicators = ["confirm√©", "vrai", "officiel", "annonc√©"]
        negative_indicators = ["d√©menti", "faux", "infond√©", "r√©fute"]
        
        score = 0
        for src in trusted_sources:
            snippet = src.get("snippet", "").lower()
            if any(word in snippet for word in positive_indicators):
                score += 1
            if any(word in snippet for word in negative_indicators):
                score -= 1
        
        if score > 0:
            verdict = "vrai"
            confidence = min(0.5 + 0.1 * score, 0.9)
        elif score < 0:
            verdict = "faux"
            confidence = min(0.5 + 0.1 * abs(score), 0.9)
        else:
            verdict = "non v√©rifiable"
            confidence = 0.5
        
        logging.info(f"   ‚úÖ Fallback verdict: {verdict} (score: {confidence:.2f})")
        
        return {
            "verdict": verdict,
            "confidence": confidence,
            "reasoning": "Analyse bas√©e sur les snippets des sources fiables.",
            "sources_used": trusted_sources,
        }
    


    def extract_json(self, text: str) -> dict | None:
        """
        Essaie d'extraire le JSON depuis un texte brut renvoy√© par Gemini.
        Retourne None si aucun JSON valide n'est trouv√©.
        """
        # Nettoyer guillemets typographiques si jamais
        text = text.replace("‚Äú", '"').replace("‚Äù", '"')
        
        # Extraire le premier bloc JSON { ... }
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if not match:
            return None
        
        json_text = match.group(0)
        
        try:
            return json.loads(json_text)
        except json.JSONDecodeError:
            return None


    # ==========================================
    # FONCTION 1: _build_context (CORRECTION)
    # ==========================================

    def _build_context(self, enriched_sources: List[Dict]) -> str:
        """
        Construit le contexte avec le CONTENU COMPLET des sources
        CORRECTION: Retourne maintenant le contexte assembl√©
        """
        if not enriched_sources:
            return "Aucune source fiable trouv√©e."
        
        context_parts = []
        
        for i, src in enumerate(enriched_sources, 1):
            # Extraire le contenu (jusqu'√† 2500 caract√®res par source)
            content = src.get('full_content', '')[:2500]
            domain = src.get('domain', 'inconnu')
            url = src.get('url', 'N/A')
            title = src.get('title', 'Sans titre')
            
            context_parts.append(f"""
    SOURCE {i}: {domain}
    URL: {url}
    TITRE: {title}
    CONTENU:
    {content}
    {"..." if len(src.get('full_content', '')) > 2500 else ""}
    ---
    """)
        
        # CORRECTION CRITIQUE: Joindre et retourner le contexte complet
        final_context = "\n".join(context_parts)
        
        # Log pour debug
        logging.info(f"üìù Contexte construit: {len(final_context)} caract√®res, {len(enriched_sources)} sources")
        
        return final_context


    # ==========================================
    # FONCTION 2: _build_intelligent_prompt (AM√âLIORATION)
    # ==========================================

    def _build_intelligent_prompt(self, rumor_text: str, context: str) -> str:
        """
        Prompt ULTIME combinant toutes les r√®gles importantes
        """
        from datetime import datetime
        current_year = datetime.now().year
        num_sources = context.count("SOURCE ")
        context_length = len(context)

        return f"""Tu es un fact-checker expert sp√©cialis√© dans les rumeurs au B√©nin.

        RUMEUR √Ä V√âRIFIER:
        "{rumor_text}"

        SOURCES FIABLES DISPONIBLES ({num_sources} sources, {context_length} caract√®res):
        {context}

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        ‚ö†Ô∏è  R√àGLE ABSOLUE DE COH√âRENCE (PRIORIT√â MAXIMALE)
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        üö´ INTERDICTIONS ABSOLUES:
        1. Ne JAMAIS mettre verdict "VRAI" si ton explication dit que la rumeur est FAUSSE
        2. Ne JAMAIS mettre verdict "FAUX" si ton explication dit que la rumeur est VRAIE
        3. Ne JAMAIS mettre score > 0.6 si tu √©cris "aucune source ne confirme" ou "rumeur est fausse"
        4. Ne JAMAIS mettre score < 0.4 si tu √©cris "sources confirment" ou "information v√©rifi√©e"
        5. Ne JAMAIS dire "aucune source fiable" alors que j'ai fourni {num_sources} sources avec contenu
        6. Ne JAMAIS laisser de listes vides (resume_sources, sources_utilisees, elements_cles)
        7. Ne JAMAIS mettre de balises markdown ```json dans la r√©ponse
        8. Ne JAMAIS dire "je n'ai pas acc√®s aux sources" - elles sont CI-DESSUS

        ‚úÖ OBLIGATION: Verdict, score ET explication doivent √™tre 100% COH√âRENTS

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üìã √âTAPES OBLIGATOIRES √Ä SUIVRE
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        1. Lis le CONTENU COMPLET de chaque SOURCE ci-dessus ({num_sources} sources)
        2. R√©sume ce que dit CHAQUE source individuellement (champ "resume_sources")
        3. Note les URLs des sources pertinentes (champ "sources_utilisees")
        4. Extrais les faits cl√©s du contenu (champ "elements_cles")
        5. D√©termine le verdict bas√© sur le CONTENU R√âEL (pas sur des suppositions)
        6. Choisis un score COH√âRENT avec ton verdict et ton explication

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üìä GUIDE DE SCORING PR√âCIS
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ RUMEUR VRAIE ‚Üí Verdict: "VRAI" + Score 0.70-1.0                    ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ ‚úì Sources CONFIRMENT explicitement la rumeur                        ‚îÇ
        ‚îÇ ‚úì Annonces officielles ou articles qui ATTESTENT le fait            ‚îÇ
        ‚îÇ ‚úì √âv√©nement mentionn√© dans plusieurs sources fiables                ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ Exemple: Rumeur "R√©forme √©lectorale annonc√©e"                      ‚îÇ
        ‚îÇ          + Sources: "Gouvernement annonce r√©forme √©lectorale"       ‚îÇ
        ‚îÇ          ‚Üí Verdict: VRAI, Score: 0.85                              ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ RUMEUR FAUSSE ‚Üí Verdict: "FAUX" + Score 0.0-0.30                   ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ ‚úì Sources D√âMENTENT explicitement la rumeur                         ‚îÇ
        ‚îÇ ‚úì ABSENCE TOTALE de mention dans toutes les sources fiables         ‚îÇ
        ‚îÇ ‚úì Sources parlent d'√©v√©nements r√©cents SANS mentionner la rumeur    ‚îÇ
        ‚îÇ ‚úì Sources contredisent directement la rumeur                        ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ Exemple: Rumeur "Palais pr√©sidentiel a br√ªl√©"                      ‚îÇ
        ‚îÇ          + Sources: Conf√©rences au palais r√©centes, z√©ro mention feu‚îÇ
        ‚îÇ          ‚Üí Verdict: FAUX, Score: 0.12                              ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ ‚ö†Ô∏è  IMPORTANT: ABSENCE de confirmation = FAUX (pas INCERTAIN!)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ INCERTAIN ‚Üí Verdict: "INCERTAIN" + Score 0.40-0.60                 ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ ‚úì Sources contradictoires (certaines confirment, d'autres d√©mentent)‚îÇ
        ‚îÇ ‚úì Informations partielles ou ambigu√´s                               ‚îÇ
        ‚îÇ ‚úì Sources insuffisantes pour trancher d√©finitivement                ‚îÇ
        ‚îÇ ‚úì Besoin de sources suppl√©mentaires                                 ‚îÇ
        ‚îÇ                                                                      ‚îÇ
        ‚îÇ Exemple: Rumeur "Ministre va d√©missionner"                         ‚îÇ
        ‚îÇ          + Sources: Un m√©dia dit oui, gouvernement ne confirme pas  ‚îÇ
        ‚îÇ          ‚Üí Verdict: INCERTAIN, Score: 0.50                         ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        R√àGLES DE SCORE STRICTES:
        - Score 0.00-0.30 ‚Üí verdict DOIT √™tre "FAUX"
        - Score 0.31-0.49 ‚Üí verdict DOIT √™tre "FAUX" (rumeur probablement fausse)
        - Score 0.50 ‚Üí verdict DOIT √™tre "INCERTAIN"
        - Score 0.51-0.69 ‚Üí verdict DOIT √™tre "VRAI" (rumeur probablement vraie)
        - Score 0.70-1.00 ‚Üí verdict DOIT √™tre "VRAI"

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        ‚ö†Ô∏è  PI√àGES √Ä √âVITER ABSOLUMENT
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        ‚ùå ERREUR 1: "La rumeur est fausse" + score 0.9
        ‚úÖ CORRECT: "La rumeur est fausse" + score 0.1-0.2

        ‚ùå ERREUR 2: "Sources confirment l'information" + score 0.2
        ‚úÖ CORRECT: "Sources confirment l'information" + score 0.8-0.9

        ‚ùå ERREUR 3: "Aucune source ne mentionne cet √©v√©nement" + verdict VRAI
        ‚úÖ CORRECT: "Aucune source ne mentionne cet √©v√©nement" + verdict FAUX

        ‚ùå ERREUR 4: "Sources d√©mentent la rumeur" + score 0.85
        ‚úÖ CORRECT: "Sources d√©mentent la rumeur" + score 0.1-0.2

        ‚ùå ERREUR 5: Liste vide dans resume_sources alors que tu as {num_sources} sources
        ‚úÖ CORRECT: R√©sumer CHAQUE source individuellement

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üåç CONTEXTE TEMPOREL
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        - Ann√©e actuelle: {current_year}
        - V√©rifie TOUJOURS les DATES dans les sources
        - Un article de 2021 parlant d'√©lections 2021 NE concerne PAS une rumeur sur 2026
        - Une conf√©rence de presse au palais en 2024 PROUVE que le palais n'a pas br√ªl√© en 2024

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üìÑ FORMAT JSON STRICT
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        {{
        "verdict": "VRAI/FAUX/INCERTAIN",
        "score_veracite": 0.0-1.0,
        "resume_sources": [
            "SOURCE 1 (nom du m√©dia): R√©sum√© de ce que dit l'article...",
            "SOURCE 2 (nom du m√©dia): R√©sum√© de ce que dit l'article...",
            "SOURCE 3 (nom du m√©dia): R√©sum√© de ce que dit l'article..."
        ],
        "explication": "Analyse d√©taill√©e COH√âRENTE avec le verdict et le score",
        "sources_utilisees": ["URL1", "URL2", "URL3"],
        "elements_cles": [
            "√âl√©ment cl√© 1 extrait du contenu",
            "√âl√©ment cl√© 2 extrait du contenu",
            "√âl√©ment cl√© 3 extrait du contenu"
        ],
        "recommandation": "Action √† prendre bas√©e sur le verdict"
        }}

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        ‚úÖ EXEMPLE COMPLET (RUMEUR FAUSSE)
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        Rumeur: "Le palais pr√©sidentiel du B√©nin a pris feu r√©cemment"

        Sources analys√©es:
        - SOURCE 1: Conf√©rence de presse au Palais de la Marina le 8 f√©vrier 2024
        - SOURCE 2: Discours du pr√©sident au palais le 20 d√©cembre 2024
        - SOURCE 3: Article Jeune Afrique janvier 2025 sur affaires politiques au palais
        - R√©sultat: Aucun article ne mentionne un incendie

        ‚úÖ BONNE R√âPONSE:
        {{
        "verdict": "FAUX",
        "score_veracite": 0.12,
        "resume_sources": [
            "SOURCE 1 (Pr√©sidence B√©nin): Transcription conf√©rence de presse du Pr√©sident Talon au Palais de la Marina le 8 f√©vrier 2024. Aucune mention d'incendie.",
            "SOURCE 2 (Pr√©sidence B√©nin): Message sur l'√©tat de la Nation prononc√© au palais le 20 d√©cembre 2024. Le palais est op√©rationnel.",
            "SOURCE 3 (Jeune Afrique): Article du 16 janvier 2025 traitant d'affaires politiques. Mentionne des √©v√©nements au palais sans aucune r√©f√©rence √† un incendie."
        ],
        "explication": "La rumeur est fausse. Aucune des trois sources fiables ne mentionne d'incendie au palais pr√©sidentiel. Au contraire, plusieurs √©v√©nements officiels se sont tenus au Palais de la Marina en 2024 et d√©but 2025 (conf√©rence de presse f√©vrier 2024, discours d√©cembre 2024, affaires politiques janvier 2025), ce qui confirme que le palais est pleinement op√©rationnel. Un incendie serait un √©v√©nement majeur qui aurait √©t√© largement relay√© par les m√©dias.",
        "sources_utilisees": [
            "https://presidence.bj/actualite/point-presse/325/",
            "https://presidence.bj/actualite/discours-interviews/363/",
            "https://www.jeuneafrique.com/1648428/politique/"
        ],
        "elements_cles": [
            "√âv√©nements officiels r√©cents au palais (f√©vrier et d√©cembre 2024)",
            "Aucune mention d'incendie dans aucune source fiable",
            "Palais utilis√© normalement pour activit√©s gouvernementales en 2025",
            "Absence de couverture m√©diatique d'un tel √©v√©nement majeur"
        ],
        "recommandation": "Rumeur infond√©e - Ne pas relayer. D√©mentir si elle se propage."
        }}

        ‚ùå MAUVAISE R√âPONSE (INTERDITE):
        {{
        "verdict": "VRAI",
        "score_veracite": 0.9,
        "explication": "La rumeur est fausse. Aucune source ne confirme...",
        "resume_sources": [],
        "sources_utilisees": []
        }}
        ‚òùÔ∏è CECI EST STRICTEMENT INTERDIT: verdict/score/explication incoh√©rents + listes vides!

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        ‚úÖ EXEMPLE COMPLET (RUMEUR VRAIE)
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        Rumeur: "R√©formes constitutionnelles annonc√©es au B√©nin"

        Sources analys√©es:
        - SOURCE 1: Article BBC mars 2024 sur r√©formes constitutionnelles
        - SOURCE 2: Article La Nation confirmant les r√©formes
        - SOURCE 3: Communiqu√© pr√©sidence sur les amendements
        - R√©sultat: Toutes les sources confirment les r√©formes

        ‚úÖ BONNE R√âPONSE:
        {{
        "verdict": "VRAI",
        "score_veracite": 0.88,
        "resume_sources": [
            "SOURCE 1 (BBC): Article du 15 mars 2024 annon√ßant que le gouvernement b√©ninois a pr√©sent√© des r√©formes constitutionnelles. Le pr√©sident Talon d√©clare vouloir moderniser le syst√®me √©lectoral.",
            "SOURCE 2 (La Nation): Article du 16 mars 2024 confirmant les annonces de r√©formes. D√©tails sur les amendements propos√©s concernant la CENI.",
            "SOURCE 3 (Pr√©sidence B√©nin): Communiqu√© officiel d√©taillant les r√©formes constitutionnelles et le calendrier de mise en ≈ìuvre."
        ],
        "explication": "La rumeur est vraie. Trois sources fiables (BBC, La Nation, Pr√©sidence du B√©nin) confirment explicitement que des r√©formes constitutionnelles ont √©t√© annonc√©es au B√©nin en mars 2024. Les articles citent des d√©clarations officielles et d√©taillent les changements propos√©s, notamment concernant le syst√®me √©lectoral et la CENI. Il s'agit d'une information v√©rifi√©e par des sources gouvernementales et des m√©dias reconnus.",
        "sources_utilisees": [
            "https://www.bbc.com/afrique/articles/reformes-2024",
            "https://lanation.bj/actualites/reformes-constitutionnelles",
            "https://presidence.bj/communiques/reformes"
        ],
        "elements_cles": [
            "R√©formes constitutionnelles officiellement annonc√©es mars 2024",
            "Confirm√© par la Pr√©sidence et m√©dias fiables internationaux",
            "Concerne le syst√®me √©lectoral et la CENI",
            "Sources dat√©es de 2024 (pertinent et r√©cent)"
        ],
        "recommandation": "Information confirm√©e - Peut √™tre relay√©e en citant les sources officielles"
        }}

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
        üîç AUTO-V√âRIFICATION FINALE (AVANT D'ENVOYER TA R√âPONSE)
        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        Pose-toi ces questions:

        1. ‚úì Mon verdict correspond-il √† mon explication?
        (Si j'√©cris "faux", est-ce que verdict = "FAUX"?)

        2. ‚úì Mon score correspond-il √† mon verdict?
        (Faux = 0.0-0.3, Incertain = 0.4-0.6, Vrai = 0.7-1.0)

        3. ‚úì Ai-je r√©sum√© TOUTES les sources fournies?
        (resume_sources doit avoir {num_sources} √©l√©ments)

        4. ‚úì Ai-je list√© les URLs utilis√©es?
        (sources_utilisees ne doit PAS √™tre vide)

        5. ‚úì Ai-je extrait des √©l√©ments cl√©s concrets?
        (elements_cles doit contenir des faits pr√©cis)

        6. ‚úì Mon JSON est-il valide sans balises markdown?
        (Pas de ```json avant ni ``` apr√®s)

        SI UNE SEULE R√âPONSE EST "NON", CORRIGE AVANT D'ENVOYER!

        ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

        MAINTENANT, ANALYSE LES {num_sources} SOURCES CI-DESSUS ET R√âPONDS EN JSON.
        """




    # ==========================================
    # FONCTION 3: verify_with_gemini (AM√âLIORATION DEBUG)
    # ==========================================

    def verify_with_gemini(self, rumor_text: str, trusted_sources: List[Dict]) -> Dict:
        """
        V√©rification intelligente avec Gemini
        VERSION AM√âLIOR√âE avec logs de debug
        """
        if not self.gemini_available:
            logging.warning("‚ö†Ô∏è Gemini non disponible, utilisation fallback")
            return self._fallback_verification(rumor_text, trusted_sources)
        
        # √âtape 1: Fetch le contenu complet
        logging.info("üì• Fetch du contenu complet des sources...")
        enriched_sources = self.fetch_all_sources(trusted_sources)
        
        if not enriched_sources:
            logging.warning("‚ö†Ô∏è Aucun contenu r√©cup√©r√©")
            return self._fallback_verification(rumor_text, trusted_sources)
        
        # √âtape 2: Construire le contexte
        context = self._build_context(enriched_sources)
        
        # DEBUG: V√©rifier que le contexte n'est pas vide
        if not context or context == "Aucune source fiable trouv√©e.":
            logging.error("‚ùå ERREUR: Contexte vide ou invalide!")
            logging.error(f"   Enriched sources: {len(enriched_sources)}")
            logging.error(f"   Context: {context[:100]}...")
            return self._fallback_verification(rumor_text, trusted_sources)
        
        logging.info(f"‚úÖ Contexte OK: {len(context)} chars, {len(enriched_sources)} sources")
        
        # √âtape 3: Construire le prompt
        prompt = self._build_intelligent_prompt(rumor_text, context)
        
        # DEBUG: Afficher un extrait du prompt
        logging.info(f"üì§ Prompt envoy√© √† Gemini ({len(prompt)} chars)")
        logging.info(f"   Extrait: {prompt[:200]}...")
        
        try:
            # Appel Gemini
            model = genai.GenerativeModel("gemini-2.5-flash")
            logging.info("ü§ñ Appel Gemini...")
            response = model.generate_content(prompt)
            text = response.text.strip()
            
            # DEBUG: Afficher la r√©ponse brute
            logging.info("üì• R√©ponse Gemini re√ßue:")
            logging.info(f"   {text[:300]}...")
            
            # Parser le JSON
            try:
                gemini_result = self.extract_json(text)
                
                if not gemini_result:
                    logging.error("‚ùå Pas de JSON valide dans la r√©ponse")
                    return self._fallback_verification(rumor_text, enriched_sources)
                
                # V√©rifier que les champs ne sont pas vides
                if not gemini_result.get("resume_sources"):
                    logging.warning("‚ö†Ô∏è resume_sources vide dans la r√©ponse Gemini!")
                if not gemini_result.get("sources_utilisees"):
                    logging.warning("‚ö†Ô∏è sources_utilisees vide dans la r√©ponse Gemini!")
                if not gemini_result.get("elements_cles"):
                    logging.warning("‚ö†Ô∏è elements_cles vide dans la r√©ponse Gemini!")
                
                # D√©terminer le verdict final
                score = gemini_result.get("score_veracite", 0.5)
                if score <= 0.49:
                    verdict = "FAUX"
                elif score == 0.5:
                    verdict = "INCERTAIN"
                else:
                    verdict = "VRAI"
                
                # Construire le r√©sultat
                result = {
                    "verdict": verdict,
                    "score_veracite": score,
                    "explication": gemini_result.get("explication", ""),
                    "sources_utilisees": gemini_result.get("sources_utilisees", []),
                    "elements_cles": gemini_result.get("elements_cles", []),
                    "resume_sources": gemini_result.get("resume_sources", []),
                    "recommandation": gemini_result.get("recommandation", "")
                }
                
                logging.info(f"‚úÖ Gemini verdict: {result['verdict']} (score: {result['score_veracite']:.2f})")
                logging.info(f"   {len(result['sources_utilisees'])} sources, {len(result['elements_cles'])} √©l√©ments cl√©s")
                
                return result
                
            except json.JSONDecodeError as e:
                logging.error(f"‚ùå Erreur parsing JSON: {e}")
                logging.error(f"   Texte re√ßu: {text[:500]}")
                return self._fallback_verification(rumor_text, enriched_sources)
        
        except Exception as e:
            logging.error(f"‚ùå Erreur Gemini: {e}")
            import traceback
            traceback.print_exc()
            return self._fallback_verification(rumor_text, trusted_sources)

# ==========================================
# SYST√àME PRINCIPAL
# ==========================================
class CorrectRumorDetectionSystem:
    def __init__(self, topics: Optional[Dict[str, List[str]]] = None, debug: bool = False, max_search_requests: Optional[int] = None, query_delay: float = 0.5):
        """
        Args:
            topics: Dictionnaire de topics personnalis√©s (optionnel)
            debug: Mode debug pour voir plus de d√©tails
        """
        self.query_generator = QueryGenerator(topics)
        self.web_searcher = WebSearcher(
            Config.GOOGLE_SEARCH_API_KEY,
            Config.GOOGLE_SEARCH_ENGINE_ID,
            max_requests=(max_search_requests or Config.MAX_SEARCH_REQUESTS),
            query_delay=(query_delay or Config.QUERY_DELAY)
        )
        self.extractor = RumorExtractor()
        self.deduplicator = RumorDeduplicator()
        self.virality_scorer = ViralityScorer()
        self.fact_checker = ImprovedFactChecker(Config.GEMINI_API_KEY, self.web_searcher)
        self.debug = debug
    
    def run_detection_cycle(self, max_queries: int = 10) -> List[Dict]:
        """Cycle complet de d√©tection

        Collecte TOUTES les rumeurs extraites (virales ou non). Les rumeurs
        non-virales auront un verdict `NON_VIRAL` et seront sauvegard√©es
        pour audit manuel.
        """
        queries = self.query_generator.generate_queries(max_queries)
        detected_rumors = []  # Toutes les rumeurs (virales ou NON)
        
        for i, query in enumerate(queries, 1):
            logging.info(f"\n{'='*70}")
            logging.info(f"üîç Recherche {i}/{len(queries)}: {query}")
            
            search_results = self.web_searcher.search(query, num_results=10)
            
            if not search_results:
                logging.info("   Aucun r√©sultat")
                continue
            
            # Filtrer sources non-v√©rifi√©es ET concernant le B√©nin
            unverified_sources = []
            for result in search_results:
                domain = domain_of_url(result.get("link", ""))
                
                if domain in Config.BLACKLIST:
                    continue
                
                if domain not in Config.TRUSTED_SOURCES:
                    # V√©rifier que le contenu concerne le B√©nin
                    full_text = f"{result.get('title', '')} {result.get('snippet', '')}"
                    
                    if self.debug:
                        logging.info(f"   üîç Analyse: {domain}")
                        logging.info(f"      Titre: {result.get('title', '')[:80]}")
                        logging.info(f"      Snippet: {result.get('snippet', '')[:80]}")
                    
                    if not is_about_benin(full_text):
                        logging.info(f"   ‚è≠Ô∏è  Ignor√© (pas sur le B√©nin): {domain}")
                        if self.debug:
                            logging.info(f"      Texte v√©rifi√©: {full_text[:100]}")
                        continue
                    
                    unverified_sources.append(result)
                    logging.info(f"   üìç Source non-v√©rifi√©e (B√©nin): {domain}")
            
            logging.info(f"   ‚û°Ô∏è  {len(unverified_sources)} sources non-v√©rifi√©es (B√©nin)")
            
            # Extraire les rumeurs
            for result in unverified_sources:
                rumor_text = self.extractor.extract_rumor_text(
                    result.get("title", ""),
                    result.get("snippet", "")
                )
                
                if not rumor_text:
                    continue
                
                if self.deduplicator.is_duplicate(rumor_text):
                    continue
                
                # Calculer viralit√©
                occurrences = 0
                for other in unverified_sources:
                    other_text = f"{other.get('title','')} {other.get('snippet','')}"
                    if jaccard_similarity(rumor_text, other_text) >= 0.25:
                        occurrences += 1

                virality_score = self.virality_scorer.score(rumor_text, occurrences)

                logging.info(f"   ‚ö†Ô∏è  RUMEUR: {rumor_text[:100]}...")
                logging.info(f"   üìå Source: {result.get('displayLink')}")
                logging.info(f"   üî• Viralit√©: {virality_score:.2f} ({occurrences} occurrences)")

                # Si la viralit√© est trop faible, on n'appelle pas le v√©rificateur
                # externe mais on ENREGISTRE quand m√™me la rumeur pour audit.
                if virality_score < Config.VIRALITY_THRESHOLD:
                    logging.info(f"   ‚è≠Ô∏è  Non-viral: viralit√© ({virality_score:.2f}) < seuil ({Config.VIRALITY_THRESHOLD})")

                    # On tente malgr√© tout une v√©rification heuristique l√©g√®re
                    # en recherchant sur les sources fiables et en utilisant
                    # la m√©thode de fallback pour produire un verdict.
                    try:
                        trusted_sources = self.fact_checker.find_trusted_sources(rumor_text)
                        verification = self.fact_checker._fallback_verification(rumor_text, trusted_sources)
                        # Indiquer que c'est une v√©rification heuristique (non-Gemini)
                        verification["verification_method"] = "heuristic_fallback"
                    except Exception as e:
                        logging.error(f"Erreur verification heuristique: {e}")
                        verification = {
                            "verdict": "INCERTAIN",
                            "score_veracite": 0.0,
                            "explication": "Erreur lors de la v√©rification heuristique",
                            "sources_utilisees": [],
                            "recommandation": "V√©rification manuelle",
                            "nb_sources_fiables": 0,
                            "verification_method": "heuristic_fallback"
                        }

                    record = {
                        "rumeur": rumor_text,
                        "virality_score": virality_score,
                        "occurrences": occurrences,
                        "source_non_verifiee": {
                            "domain": result.get("displayLink", ""),
                            "url": result.get("link", ""),
                            "titre": result.get("title", "")
                        },
                        "verification": verification,
                        "detected_at": datetime.now(timezone.utc).isoformat(),
                        "note": "NON_VIRAL"
                    }
                    detected_rumors.append(record)
                    continue

                # V√©rifier avec sources fiables
                logging.info(f"   üî¨ V√©rification...")
                trusted_sources = self.fact_checker.find_trusted_sources(rumor_text)
                verification = self.fact_checker.verify_with_gemini(rumor_text, trusted_sources)
                
                verdict = verification.get("verdict", "?")
                score = verification.get("score_veracite", 0)
                nb_sources = verification.get("nb_sources_fiables", 0)
                
                if verdict == "FAUX":
                    logging.info(f"   ‚ùå FAUX (score: {score:.2f}, {nb_sources} sources)")
                elif verdict == "VRAI":
                    logging.info(f"   ‚úÖ VRAI (score: {score:.2f}, {nb_sources} sources)")
                else:
                    logging.info(f"   ‚ö†Ô∏è  {verdict} ({nb_sources} sources)")
                
                # Enregistrer SEULEMENT si viral
                record = {
                    "rumeur": rumor_text,
                    "virality_score": virality_score,
                    "occurrences": occurrences,
                    "source_non_verifiee": {
                        "domain": result.get("displayLink", ""),
                        "url": result.get("link", ""),
                        "titre": result.get("title", "")
                    },
                    "verification": verification,
                    "detected_at": datetime.now(timezone.utc).isoformat()
                }
                
                detected_rumors.append(record)
                time.sleep(0.5)
        
        return detected_rumors
    
    def save_results(self, records: List[Dict], filename: str = Config.OUTPUT_FILE):
        """Sauvegarde les r√©sultats"""
        # √âcrire le fichier √† c√¥t√© du script pour √©viter les confusions de cwd
        base_dir = os.path.dirname(__file__) or os.getcwd()
        out_path = os.path.join(base_dir, filename)
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(records, f, ensure_ascii=False, indent=2)
        logging.info(f"\nüíæ {len(records)} rumeurs sauvegard√©es: {out_path}")




